# Python_Bi-LSTM_Attention
## 基于深度学习Python_Bi-LSTM_Attention的招聘与求职双向推荐模型
### 一、摘要
###### 近年来，python 作为一门编程语言，提供了高速的高级数据结构，以及简单有效地面向对象编程，随者人工智能和大数据的发展，python 逐渐成为流行 的编程语言；在新时代背景下，大学生毕业人数不断增加，大学生求职问题已成为广泛关注的社会热点。而且受疫情影响，诸多企业的招聘都改为线上进行，脱离时间和空间的限制，招聘需求不断上涨，从而出现就业竞争压力大、招聘与求职信息不对称等现象，双向职业推荐模型连接了企业与求职者的需求，利用 python语言对竞双向职业推荐模型的建立具有重大意义。
###### 通过从泰迪内推平台（https://www.5iai.com/#/index）的“找工作”页面和“找人才”页面，爬取所有招聘与求职信息并整理并形成文件：result1-1.csv以及 result1-2.csv，数据的爬取主要采用了 python 的爬虫技术。
###### 为了能准确的形成双向推荐模型我们们结合了 BI-LSTM 算法、文本匹配、Attention-LSTM 模型进行实现，基于 python 爬取得信息数据，我们对数据得空缺值处理以及异常值进行了处理，最后我们使用里 python 的 matplotlib 库、seaborn 库、对数据信息进行多个维度的用户画像，对数据之间的关系进行了数据可视化分析。基于预处理后的数据，构建岗位匹配度和求职者满意度的模型，使用 BI-LSTM 算法、文本匹配等算法，计算两表中的岗位匹配度以及满意度，每条招聘信息提供岗位匹配度非 0 的求职以及每位求职者提供求职者满意度非 0的招聘信息存放在指定的表格中。

### 二、章节安排
###### 根据前面相关内容的分析，我们针对用户企业双向推荐模型的研究思路主要从几节相应介绍：
###### 1） 第 3 主要介绍我们对泰迪内推网站的数据爬取过程
###### 2） 第 4 主要是介绍我们第二题的求职者以及企业多个维度的用户画像，使用matplotlib 库、seaborn 库，进行图像绘画。
###### 3） 第 5 主要介绍我们第三题的构建岗位匹配度和求职者满意度的模型，使用BI-LSTM 算法、文本匹配、Attention-LSTM 模型等

### 三、相关技术
##### 1、动态爬虫
###### 动态爬取是指爬取动态网页内容，包括通过 JavaScript 加载的内容。实现动态爬取的方法有以下几种：
###### 1. 使用 Selenium：Selenium 是一个自动化测试工具，可以模拟用户在浏览器中的操作，包括点击、输入、滚动等。通过 Selenium 可以启动一个浏览器，加载网页并执行 JavaScript，然后获取网页内容。Selenium 支持多种浏览器，包括 Chrome、Firefox、Safari 等。
###### 2. 使用 Pyppeteer：Pyppeteer 是一个 Python 库，可以通过调用 Chrome DevTools 协议来控制 Chrome 浏览器。Pyppeteer 可以启动一个 Chrome 浏览器，加载网页并执行 JavaScript，然后获取网页内容。Pyppeteer 的性能比 Selenium 更好，但需要安装 Chrome 浏览器。
###### 3. 使用 Requests-HTML：Requests-HTML 是一个 Python 库，可以发送 HTTP 请求并解析 HTML 内容。Requests-HTML 支持 JavaScript 渲染，可以通过调用浏览器引擎来执行 JavaScript，并获取渲染后的 HTML 内容。Requests-HTML 的性能比 Selenium 和 Pyppeteer 更好，但不支持所有的 JavaScript 特性。
###### 4. 使用 Splash：Splash 是一个轻量级的 JavaScript 渲染服务，可以通过 HTTP API 调用。Splash 可以启动一个浏览器，加载网页并执行 JavaScript，然后返回渲染后的 HTML 内容。Splash 支持多种浏览

##### 2、Numpy
###### NumPy（Numerical Python）是Python的一种开源的数值计算扩展。这种工具可用来存储和处理大型矩阵，比Python自身的嵌套列表（nested list structure)结构要高效的多（该结构也可以用来表示矩阵（matrix）），支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。

##### 3、Pandas
###### pandas 是基于NumPy 的一种工具，该工具是为解决数据分析任务而创建的。Pandas 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。pandas提供了大量能使我们快速便捷地处理数据的函数和方法。

##### 4、Pyecharts
######  Pyecharts是一款将python与echarts结合的强大的数据可视化工具。使用 pyecharts 可以生成独立的网页,也可以在 flask , Django 中集成使用。

##### 5、Matplotlib 库
###### Python 开发中是专门用于开发 2D 图表(包括 3D 图表) 以渐进、交互式方式实现数据可视化，它以各种硬拷贝格式和跨平台的交互式环境生成出版质量级别的图形，可视化是在整个数据挖掘的关键辅助工具，可以清晰的理解数据，从而调整我们的分析方法。 能将数据进行可视化,更直观的呈现 使数据更加客观、更具说服力。

##### 6、BI-LSTM 算法
###### 前向的 LSTM 与后向的 LSTM 结合成 BiLSTM[1]，结构如下图 1 所示。前向 LSTM可以获取输入序列的过去数据信息，后向 LSTM 可以获取输入序列的过去数据信息，对时间序列实现向前和向后两次 LSTM 训练，进一步提高特征提取的全局性和完整性。
###### LSTM 的全称是 Long Short-Term Memory,它是 RNN 的一种。LSTM 模型是由 t时刻的输入词 Xt，细胞状态 Ct，临时细胞状态 Ct，隐层状态 ht，遗忘门 ft ，记忆门 it，输出门 ot 组成。LSTM 的计算过程可以概括为，通过对细胞状态中信息遗忘和记忆新的信息使得对后续时刻计算有用的信息得以传递，而无用的信息被丢弃，并在每个时间步都会输出隐层状态 ht，其中遗忘、记忆与输出由通过上个时刻的隐层状态 ht−1 和 X t 当前输入计算出来的遗忘门 ft，记忆门 it，输出门 ot 来控制。总体框架如下图 2-2：

##### 7、文本匹配
###### 文本匹配旨在从两端文本中挖掘内在的语义特诊，预测文本间相关行或者矛盾性。文本匹配任务是自然语言处理中重要的研究方向，无论是在信息检索、问题回答还是复述识别等任务中都扮演着重要角色。传统的文本匹配方法依赖于预定义的模板和人工提取的规则。随着深度学习的发展，深度神经网络已经普遍应用于自然语言处理任务中，以节省人工提取特征所耗费的成本和时间。文本匹配任务旨在给定两段文本Ｑ和Ｄ，通过提取文本中存在的语义信息和相似度特征来给出两段文本的相似度值，由最终的相似度值可以得知两段文本的内容是否属于相似的描述。基于深度学习的文本匹配模型大致可以分为两类：基于表示的文本匹配模型和基于交互的文本匹配模型。基于表示的文本匹配模型通过对文本进行预处理以及构建索引，能够更好地提取每段文本里面的信息，但是在信息表示的过程中容易失去语义焦点，难以衡量词在上下文中的重要性。基于交互的文本匹配模型虽然可以较好地把握语义焦点，针对上下文进行更好的建模，但是却忽视了全局信息，会造成无法刻画出全局匹配信息的后果[2]

##### 8、Attention-LSTM 模型
###### 将 LSTM 层的输出向量作为 Attention 层的输入。注意力机制的本质为计算某一特征向量的加权求和。 本文采用的是乘法注意力机制中的 ScaledDot-Product Attention 方法，其计算主要分为 3 个步骤：
###### 1. 将 query 和每个 key 进行点积计算得到权重
###### 2. 使用 Softmax 函数对权重归一化处理。
###### 3. 将权重和对应的 value 加权求和获得 Attention 。

##### 9、tensorflow 库
###### TensorFlow 是一个基于数据流编程（dataflow programming）的符号数学系统，被广泛应用于各类机器学习（machine learning）算法的编程实现，其前身是谷歌的神经网络算法库 DistBelief。Tensorflow 拥有多层级结构，可部署于各类服务器、PC 终端和网页并支持 GPU 和 TPU 高性能数值计算，被广泛应用于谷歌内部的产品开发和各领域的科学研究 。

##### 10、Tableau 可视化软件
###### Tableau 是能够帮助大家查看并理解数据的商业智能软件。 快速分析 在数分钟内完成数据连接和可视化。Tableau 比现有解决方案快 10 到 100 倍。 简单易用，任何人都可以使用。

### 四、招聘信息数据源的确定
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/012a5037-56f3-452a-8a9a-bb74138ee517)

### 五、网络爬虫的基本流程
#### 1、招聘信息数据源的确定
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/61003958-1d67-4037-909e-dc6851f4e1ef)

![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/79b7048f-9deb-4c45-8ac5-030d6d87ba1f)
###### 平台页面分析主要分为页面结构分析和内容分析两部分。页面结构分析主要包括以下方面：爬取目标页面是静态还是动态的；确定请求方式。内容分析是确定需要采集的内容在页面的什么位置，主要有两种情况：一是待采集的内容就在当前页面，可以直接爬取；二是待采集的内容需要提前制定采集规则[3]，利用当前页面进行跳转获取。信息爬取分为两步，发送请求和获取响应目标内容。利用Python 模拟浏览器对网页发出请求时主要使用 requests 库，请求方式为 get。返回请求成功时通过 json 形式获取响应的文本数据。数据解析是对获取到的数据进行内容判断和字段提取，选取具有分析价值的字段，由于平台数据格式较为规整，最后将解析后的数据保存到 csv 文件中，分别为 result1-1.csv 和result1-2.csv。

#### 2、数据类招聘信息的采集
##### 2.1 平台页面分析
###### 本文使用爬虫程序的目的是采集内推网站的岗位招聘信息和求职信息。在编写爬虫序之前需要根据采集内容确定网页位置，并从页面结构和内容两方面对其进行分析。
###### （1）网页结构分析
###### 网页结构分为以下部分：爬取目标页面是静态还是动态的，确定请求方式，是否存在反爬措施。判断爬取目标页面是静态还是动态的可以通过爬取部分头部信息，根据爬取的 body 和 JavaScript 跳转得出需要使用动态爬虫；通过 F12观察 network 请求列表得到爬取两大网站的规律：pageNumber 表示浏览的页面为分页模块的第几页面，PageSize 表示当前浏览页面的数据量，点击请求链接和响应标头部分发现该链接的请求方式是 get。
###### （2）内容分析
###### 泰迪内推“找工作”页面筛选条件主要有职位和企业两部分，通过观察职位页面的招聘数据得出每一条招聘信息包含工作岗位名称、薪资范围、学历要求、工作经验、招收人数、公司名称、公司类型、公司规模、发布时间和职位关键词等 10 类信息。职位页面每一页最多显示 10 条招聘信息，共 158 页数据，累计1574 条招聘信息。企业页面主要是企业的基本信息，包含企业名称、职位关键词、企业规模和招收人数 4 类信息，每一页最多显示 16 家企业信息，共 36 页数据，累计 568 条招聘信息。本次需要采集的数据为内推网站的招聘信息，通过对比分析发现求职页面信息包含企业页面信息，经过初步分析后决定爬取求职页面中的招聘信息。
##### 2.2 信息爬取
###### 通过对内推网站的页面结构和内容分析，将进一步爬取目标信息，使用requests 库的 get 方法向浏览器发出请求，其使用 requests 方法的语法格式如下：response=request.get(‘目标网址’)。请求成功后获取响应的文本数据，将请求到的数据存储为 json 格式文件，爬取岗位详情页面过程中发现第 91 个页面后出现大量的完全空页，使用 Python 代码观察 min(os.path.getsize(path))发现完全空页文件大小在 44-48 字节之中，直接对文件大小进行判断：文件大于50 字节且拥有关键的目标值才对其进行处理，否则均给空值。
##### 2.3 数据解析
###### 浏览 json 文件下的 data 目标数据发现有我们需要进一步分析的数据"工作id", "工作更新时间", "工作岗位名称", "工作岗位最低工资", "工作岗位最高工资", "工作岗位要求经验", "工作岗位要求学历", "工作岗位招收人数", " 工作岗位具体地址","公司名称", "公司所属类型", "公司成立模式", "公司规模"等，由于大部分数据在 content 目录下，直接通过列表索引或切片索引进行目标数据的获取。将获取到的所有岗位数据根据 id 划分到每一个列表子目录下，依据 id 排序划分到总列表，将其分别保存至 csv 文件中，文件分别为“result1-1.csv”和“result1-2.csv”。招聘信息保留招聘信息 ID、公司名称、招聘岗位、工作岗位最低工资、工作岗位最高工资、工作岗位要求经验、工作岗位要求学历、工作岗位招收人数、工作岗位具体地址、公司所属类型、公司成立模式、公司规模和岗位技能等 13 个字段特征；求职信息保留求职者 ID、姓名、性别、应聘工作岗位、工作经验、最低薪资期望、最高薪资期望、所在城市、上传时间和个人技能等 10 个字段特征来做进一步分析。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/01c33fbc-b2c3-412e-95fa-56819d695adf)

#### 3、招聘与求职信息分析
##### 3.1 数据预处理
###### 从泰迪内推平台的“找工作”页面和“找人才”页面，爬取的数据，较为规整，但为了能让计算机简单有效地处理文本信息，需要对原始的数据变得有规则、有结构、有组织的数据，需要进行数据预处理。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/ad64d478-b426-4906-af94-61c286787d0d)
###### 泰迪内推网站中“找工作”页面中，每条职位招聘信息排版样式如上图所示，顶部为岗位名称、薪资范围、学历要求、岗位要求、招聘人数、岗位发布时间、投递截止时间等基本信息；左下侧为职位关键词、技能要求、职位描述等具体信息，右侧为公司的基本信息，包括所属行业、公司名称、公司类型等。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/c07daa94-fb0b-4694-99c7-58cbc5aeb5a7)
###### 泰迪内推网站中“找人才”页面中，每条求职信息排版样式如上图所示，顶部为期望岗位名称、期望薪资；左侧求职者的基本信息，包括姓名、性别、年龄、工作经验、政治面貌、求职意向、简历关键词、工作经历、项目经历、竞赛经历等具体求职信息。
##### 3.1.1 数据清洗
###### 对所得的数据进行缺失值的处理，减少缺失值对画像的不准确性，在分析求职者以及企业招聘数据时，使用 python 的 isnull 对数据的每一列进行计算缺失值，相关数据中并没有出现缺失值，如果相关数据大部分为空值，删去相关的空值数据。

##### 3.2 企业招聘信息
##### 3.2.1 招聘岗位分析
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/8dc04749-a956-4fc7-a8bc-d205e60a09a8)
###### 由于招聘信息中企业发布的工作岗位数据类型较多，本文截取主要的职位进行展示，通过统计的数据可以看出在“大数据+”和“人工智能”领域中，对“数据分析”、“计算机”、“数据产品”、“GIS”类的岗位需求较大，“直播”、“游戏”、“客服”等非计算机类型岗位也有一定需求，求职者可以在该平台上获取适合自身的岗位信息。
##### 3.2.2 学历要求分析
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/74ecb803-ebea-41f1-9c52-6a122b088ae4)
###### 根据爬取的招聘信息统计结果可知，招聘信息学历要求最多的是本科，高达78.0%，17.2%的招聘信息要求学历为大专，发布的招聘信息中对学历没有要求占比为 0.6%，相反，要求硕士学历占比 3.3%，硕士，博士的比例都低于 10%，因此可以说明大多数企业招聘对学历要求是不高的；由上图可以看出，本科和大专的占比是比较大的，企业多为小型或中型企业，从企业招聘现实状况来看，学历要求更多的是本科和大专，博士和硕士相对而言需求较少。
##### 3.2.3 公司成立模式分析
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/1ad2f153-29a5-4401-850c-418d29af439b)
##### 3.2.4 公司规模统计
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/a0684718-6639-4bd7-aaf9-a909b902d6cb)
###### 对获取到的数据 统计 xx 发布数据类岗位企业的规模占比，结果如图 所示。从图可以发现，规模为 50—100 人的企业最多，占比 78.7%，其次是规模为 150 —500 人的企业，占比为 8.4%。规模为 1000—1500 人的企业占比最少，占比 0.1%。说明当前的企业规模主要分布在 50—500 人之间，企业大多数处于发展阶段，只有较少部分企业规模较大。
##### 3.2.5 薪资待遇与工作经验、学历要求
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/f8e39783-0773-496b-8e23-5af8db60f8d6)
###### 根据泰迪内推平台上的招聘信息将工作经验要求划分为以下几种类型：经验不限、1-3 年、3-5 年、5-7 年、5-19 年、7 年以上、10 年。从图中可以看出 5-10年的工作经验对薪资的提升有很大优势，无论是最低薪资待遇还是最高薪资期望待遇，薪资随着经验年限的增加而不断增长，这可能跟互联网 IT 行业发展时间阶段有关，由于互联网行业近十年来发展较快，技术和专业知识不断更新，所以对该行业方面的经验需求还是比较大的。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/9fc7cbab-6036-462f-878e-c3180334be53)
###### 除了上述工作经验会影响薪资，学历要求也是薪资待遇要关注的部分，从图中可以看出在最低薪资待遇里，越高学历的求职者在薪资方面有很大程度的晋升空间，这说明大多数企业对求职者的学历还是比较看重，在高薪资待遇里并非越高学历者薪资越高，据观测，在高薪资待遇里，求职者是已经适应过一段时间的工作培训和工作任务，更多看重的是工作能力和技术而并非学历。
##### 3.2.6 岗位技能分析
###### 对招聘信息中的“岗位技能”做进一步分析统计，细分不同工作岗位名称并加以统计。筛选排除部分没有技能要求的岗位后总共得出有 232 个岗位对技能有要求，标记按工作岗位名称不同计数进行标记，颜色深浅作为工作岗位需要该技能的计数体现，颜色越深代表该技能在岗位的重要性，得出的岗位技能热力图如下图所示。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/9f1c7aaf-c5c0-4575-abd9-485d0e410df4)
###### 由上图可以看出，大多数公司工作岗位对岗位技能要求较多的是“数据开发”能力，其中“项目管理需求分析”能力和“项目管理”能力也占据重要地位，可以说明在数据开发能力和分析能力是当前“大数据”和“人工智能”领域不断向前发展的重要动力。为进一步筛选岗位技能要求，本文以“广东省”为例，对招聘信息中的工作岗位具体地址、岗位技能等字段分别进行统计分析，筛选出所有的大数据职位与其对应 id，按照 id 将职位描述表中相应的大数据职位的岗位描述和任职要求提取出来，然后利用 jieba 对这些文本进行分词，由于文本中有大量的专业术语如：“数据分析”“数据挖掘”“云计算”等，需要添加自定义的用户词典，将这些专业术语添加进去并词频统计绘制出对应数据的词云图，通过颜色对不同词汇作出区分，根据字体大小强调了词汇的出现频率，字体越大的汇在岗位技能要求中被提及的次数最多，同时将词云图设计成省份的形状，暗示了企业需要岗位技能要求分布的区域。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/0098ec2c-4797-4b08-a493-60ddaec6a0eb)
###### 根据图可以看出。“数据”、“数据分析”、“可视化”、“预处理”、“数据挖掘”、“探索”等词语出现频数较大，说明广东省中大多数企业招聘需要的人才需具有良好的数据分析能力，另外，“计算机”、“神经网络”、“测试”等词语也有一定程度的展现。说明招聘岗位对专业知识也有一定要求。
##### 3.2.7 招聘信息画像
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/6a5b8274-acf5-4351-b4ff-e7e57ee8adbb)
###### 通过上述的统计分析描述，招聘信息画像由招聘信息中多维度数据结合而成，主要的画像数据包含公司规模、公司成立模式、企业招聘工作经验要求、学历要求、学历对应岗位的最低薪资和最高薪资待遇、工作经验要求下最低工资和最高工资待遇以及岗位需求量，求职者可通过招聘信息画像匹配符合自身的岗位。

##### 3.3 求职者求职信息
##### 3.3.1 预期岗位
###### 根据爬取到的求职者求职信息进行统计分析，求职者求职信息包含“求职者ID”、“姓名”、“应聘工作岗位”、“性别”、“工作经验”、“最低薪资期望”、“最高薪资期望”、“所在城市”、“上传时间”、“个人技能”等 10项数据。下表为截取的部分数据。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/e0c6278d-99d4-4d26-81db-5a66181d3c5e)
###### 首先对求职信息中的“求职岗位”进行分析，由于统计数据文本中有大量的专业术语如：“数据分析师”“数据挖掘工程师”“算法工程师”等，需要添加自定义词典，将这些专业术语添加进去，然后再进行分词，统计高频词汇，由于不同求职者的求职岗位不同，本次提取出前八位的岗位进行分析，从上表可以看出，“数据分析师”出现频率最高，达到 10844 次，其次是“数据挖掘工程师”，可以看出在“大数据”和“人工智能”领域，求职者岗位意向更多的是关于数据分析和处理方面内容，最后生成的整体预期岗位词云图如图所示。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/0279e1b8-8338-4c55-82c7-c5f53e1f2750)
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/f25b25b5-8101-4da4-9aeb-7f91cd7b8433)
###### 为精确分析求职者的岗位期望，本文依据求职者求职信息中的“性别”字段，分别进行预期岗位的分析。求职信息中获取到的男性数据为 1190 条，女性数据为 975 条。分别使用 collections 库中的 Counter()函数对男性女性数据进行词汇统计，提取出关键词后使用 wordcloud 库绘制对应期望岗位词云图。从图中可以看出男性期望岗位出现频率较高的是“数据分析师”、“数据挖掘工程师”、“Hadoop 大数据开发工程师”等，字体大小强调了词汇的出现频率，字体越大的词汇表示在期望岗位中提及的次数最多。

##### 3.3.2 薪资需求
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/d5ceb103-9c7b-4f36-9c17-875b5cd350ee)
###### 图中可以看出男性薪资期望无论是最高期望还是最低期望，其薪资期望都低于 20000，最高薪资期望比较分散，最低薪资期望分布比较集中，从上下四位数的间距可以看出最低薪资期望分布是平衡的，最高薪资期望则不平衡，最高薪资出现 2 个异常点，最低薪资出现 3 个异常点，但从总体看来最高薪资期望和最低薪资期望两者相差不大，说明男性在薪资期望过程中保持较为平稳的状态。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/ef960238-0acc-4801-94da-aec1d82740ed)
###### 从男性薪资幅度图可以看出最高薪资期望和最低薪资期望之间有一定的距离幅度，最高薪资和最低薪资变化幅度趋势大致一样，两者在 4285—4310 区域之间变化较为平缓，工资越高则两则变化幅度都比较大。侧面说明工资幅度在到达一定程度后会发生较大改动。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/f99c8842-f245-4587-976c-bf1cadcfe80b)
###### 图中可以看出女性薪资期望无论是最高期望还是最低期望，其薪资期望都低于 16000，最高薪资期望比较分散，最低薪资期望分布比较集中，从上下四位数的间距可以看出最低薪资期望分布是平衡的，最高薪资期望则不平衡，女性最高薪资期望出现 1 个异常点，最低薪资出现 2 个异常点，但从总体看来最高薪资期望和最低薪资期望两者相差不大，说明女性在薪资期望过程中保持较为平稳发展的状态。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/256b45d8-ddf8-4feb-be59-8efe80b5d78d)
###### 从女性薪资幅度图可以看出最高薪资期望和最低薪资期望之间有一定的距离幅度，最高薪资和最低薪资变化幅度趋势大致一样，两者在薪资变化上一直都有较大的波动。侧面说明在薪资上可能会出现较大差异。

##### 3.3.3 知识储备
###### 在进行“个人技能”统计情况中，发现“个人技能”一块出现数据空白，因此需要对空白数据值进行清理，删除空值数据 10279 条，剩余男性数据 180 条，女性数据 184 条。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/c1a35899-b747-4f4a-926c-6f0258921a91)
###### 根据求职者求职信息的统计结果可知，拥有“数据预处理”能力的人数最多，“数据探索”和“数据分析”能力位列第二第三。依次为“数据可视化”、“数据建模”、“数据采集”、“神经网络”、“图像处理”、“自然语言处理”。
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/3ae79fc2-e5d1-4c9e-9681-f04b945c11df)
![image](https://github.com/Chloe010/Python_Bi-LSTM_Attention/assets/129756356/22775e0f-4e61-40ef-852b-ce63719b4ba2)

##### 3.3.4 用户户籍分布


#### 4、构建岗位匹配度和求职满意度的模型





















